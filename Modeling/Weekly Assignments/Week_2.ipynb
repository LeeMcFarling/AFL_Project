{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec67006",
   "metadata": {},
   "source": [
    "# **Week 2**\n",
    "\n",
    "Lasso, Ridge, and Elastic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59e6da",
   "metadata": {},
   "source": [
    "#### **Package Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c266f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    "    RepeatedKFold\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "# Progress Tracking\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2bec8",
   "metadata": {},
   "source": [
    "#### **Dataset Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e20c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BDB_All_Plays_Model_Ready = pd.read_csv(\"../../AFL_Final_Project/BDB_All_Plays_Model_Ready.csv\") # Big Data Bowl Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312430d5",
   "metadata": {},
   "source": [
    "#### **Getting Started: Decisions Made Thus Far**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde51677",
   "metadata": {},
   "source": [
    "The 'Big Data Bowl' dataset is the most difficult of the three football datasets to work with, but it is also the most feature rich. The following is a collection of observations and datapoints made thus far. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f005670",
   "metadata": {},
   "source": [
    "#### **1. Numeric Data Correlation with the target Variable: *Inj_Occurred***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b74932",
   "metadata": {},
   "source": [
    "Bi and multivariate analysis in Semester 2 showed that none of the numeric fields had a strong correlation with the target variable, aside from the foulID columns. These were later encoded into Foul Flag columns (six seperate foul ID columns were present, each containing redundant information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58609003",
   "metadata": {},
   "source": [
    "![Corr Matrix](\"https://github.com/LeeMcFarling/AFL_Project/Modeling/Weekly%20Assignments/Corr_Matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972edef",
   "metadata": {},
   "source": [
    "#### **2. Categorical Relation to target Variable**\n",
    "\n",
    "The following columns have low p-vlaues meaning their relationship with the target variable is considered not due to chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c3656",
   "metadata": {},
   "source": [
    "![Categorical Features](https://raw.githubusercontent.com/LeeMcFarling/AFL_Project/main/Modeling/Weekly%20Assignments/Categorical_Features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe449b",
   "metadata": {},
   "source": [
    "#### **3. VIF Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f8ebe",
   "metadata": {},
   "source": [
    "The following features were dropped because they had extremely high VIF values, even after multicollinearity drops in dummie variable creation were done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd1a78",
   "metadata": {},
   "source": [
    "- pff_cassCoverage - VIF scores so high it was litterally off the charts\n",
    "- personnelO - VIF scores so high it was literally off the charts\n",
    "- personnelD - Highly correlated with other defensive stats. \n",
    "- prePenaltyPlayResult - similar to play result\n",
    "- defendersInBox -High VIF but not highly correlated with target\n",
    "- quarter - Highly correlated with other time variables but not with target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dbba1",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996494b8",
   "metadata": {},
   "source": [
    "#### **Function Definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a01b90",
   "metadata": {},
   "source": [
    "Function to take a provided dataframe and split that dataframe into feature and target columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e99be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================================\n",
    "# Function taken from Module 3 Final Project\n",
    "# https://github.com/LeeMcFarling/Final_Project_Writeup/blob/main/Final_Project_Report.ipynb\n",
    "# ===========================================================================================\n",
    "\n",
    "def train_test_split_data(df, target_col):\n",
    "    X = df.drop(columns=target_col)\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5d1c1",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa59b24",
   "metadata": {},
   "source": [
    "#### **Lists to split Data into Numeric and Categorical Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90654dde",
   "metadata": {},
   "source": [
    "Because we already made one hot encoded variables here are lists to seperate numeric and categorical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8deb7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    " 'down',\n",
    " 'yardsToGo',\n",
    " 'yardlineNumber',\n",
    " 'preSnapHomeScore',\n",
    " 'preSnapVisitorScore',\n",
    " 'penaltyYards',\n",
    " 'playResult',\n",
    " 'absoluteYardlineNumber',\n",
    " 'frac_quarter_elapsed']\n",
    "\n",
    "categorical_columns = [\n",
    " 'possessionTeam_ATL',\n",
    " 'possessionTeam_BAL',\n",
    " 'possessionTeam_BUF',\n",
    " 'possessionTeam_CAR',\n",
    " 'possessionTeam_CHI',\n",
    " 'possessionTeam_CIN',\n",
    " 'possessionTeam_CLE',\n",
    " 'possessionTeam_DAL',\n",
    " 'possessionTeam_DEN',\n",
    " 'possessionTeam_DET',\n",
    " 'possessionTeam_GB',\n",
    " 'possessionTeam_HOU',\n",
    " 'possessionTeam_IND',\n",
    " 'possessionTeam_JAX',\n",
    " 'possessionTeam_KC',\n",
    " 'possessionTeam_LA',\n",
    " 'possessionTeam_LAC',\n",
    " 'possessionTeam_LV',\n",
    " 'possessionTeam_MIA',\n",
    " 'possessionTeam_MIN',\n",
    " 'possessionTeam_NE',\n",
    " 'possessionTeam_NO',\n",
    " 'possessionTeam_NYG',\n",
    " 'possessionTeam_NYJ',\n",
    " 'possessionTeam_PHI',\n",
    " 'possessionTeam_PIT',\n",
    " 'possessionTeam_SEA',\n",
    " 'possessionTeam_SF',\n",
    " 'possessionTeam_TB',\n",
    " 'possessionTeam_TEN',\n",
    " 'possessionTeam_WAS',\n",
    " 'defensiveTeam_ATL',\n",
    " 'defensiveTeam_BAL',\n",
    " 'defensiveTeam_BUF',\n",
    " 'defensiveTeam_CAR',\n",
    " 'defensiveTeam_CHI',\n",
    " 'defensiveTeam_CIN',\n",
    " 'defensiveTeam_CLE',\n",
    " 'defensiveTeam_DAL',\n",
    " 'defensiveTeam_DEN',\n",
    " 'defensiveTeam_DET',\n",
    " 'defensiveTeam_GB',\n",
    " 'defensiveTeam_HOU',\n",
    " 'defensiveTeam_IND',\n",
    " 'defensiveTeam_JAX',\n",
    " 'defensiveTeam_KC',\n",
    " 'defensiveTeam_LA',\n",
    " 'defensiveTeam_LAC',\n",
    " 'defensiveTeam_LV',\n",
    " 'defensiveTeam_MIA',\n",
    " 'defensiveTeam_MIN',\n",
    " 'defensiveTeam_NE',\n",
    " 'defensiveTeam_NO',\n",
    " 'defensiveTeam_NYG',\n",
    " 'defensiveTeam_NYJ',\n",
    " 'defensiveTeam_PHI',\n",
    " 'defensiveTeam_PIT',\n",
    " 'defensiveTeam_SEA',\n",
    " 'defensiveTeam_SF',\n",
    " 'defensiveTeam_TB',\n",
    " 'defensiveTeam_TEN',\n",
    " 'defensiveTeam_WAS',\n",
    " 'passResult_I',\n",
    " 'passResult_IN',\n",
    " 'passResult_R',\n",
    " 'passResult_S',\n",
    " 'offenseFormation_I_FORM',\n",
    " 'offenseFormation_JUMBO',\n",
    " 'offenseFormation_PISTOL',\n",
    " 'offenseFormation_SHOTGUN',\n",
    " 'offenseFormation_SINGLEBACK',\n",
    " 'offenseFormation_WILDCAT',\n",
    " 'dropBackType_DESIGNED_ROLLOUT_RIGHT',\n",
    " 'dropBackType_DESIGNED_RUN',\n",
    " 'dropBackType_SCRAMBLE',\n",
    " 'dropBackType_SCRAMBLE_ROLLOUT_LEFT',\n",
    " 'dropBackType_SCRAMBLE_ROLLOUT_RIGHT',\n",
    " 'dropBackType_UNKNOWN',\n",
    " 'pff_passCoverageType_Other',\n",
    " 'pff_passCoverageType_Zone',\n",
    " 'pff_playAction',\n",
    " 'Inj_Occured',\n",
    " 'foul_on_play',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133d0dd",
   "metadata": {},
   "source": [
    "#### **Standardization Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16b3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Standardize Numeric Features\n",
    "# \n",
    "# Taken from Mod 3 final project found here: \n",
    "# https://github.com/LeeMcFarling/Final_Project_Writeup/blob/main/Final_Project_Report.ipynb\n",
    "#\n",
    "# Note: some errors were calling so I just hard coded it. \n",
    "# =============================================================================================\n",
    "\n",
    "def standardize_features(df, target_column=None, debug=False, return_scaler=False):\n",
    "    df_scaled = df.copy()\n",
    "    numeric_cols  = [\n",
    "                        'down',\n",
    "                        'yardsToGo',\n",
    "                        'yardlineNumber',\n",
    "                        'preSnapHomeScore',\n",
    "                        'preSnapVisitorScore',\n",
    "                        'penaltyYards',\n",
    "                        'playResult',\n",
    "                        'absoluteYardlineNumber',\n",
    "                        'frac_quarter_elapsed']\n",
    "\n",
    "    if target_column in numeric_cols:\n",
    "        numeric_cols.remove(target_column)\n",
    "\n",
    "    # Step 4: Further exclude binary (0/1) columns\n",
    "    numeric_cols_to_scale = [\n",
    "        col for col in numeric_cols\n",
    "        if df[col].nunique(dropna=True) > 2\n",
    "    ]\n",
    "\n",
    "    # DEBUG\n",
    "    if debug:\n",
    "        print(\"Numeric columns before filtering:\", numeric_cols)\n",
    "        print(\"Numeric columns after filtering:\", numeric_cols_to_scale)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled[numeric_cols_to_scale] = scaler.fit_transform(df_scaled[numeric_cols_to_scale])\n",
    "\n",
    "    if return_scaler:\n",
    "        return df_scaled, scaler\n",
    "\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a09c98",
   "metadata": {},
   "source": [
    "#### **Run Model Classifier** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3182db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Taken from Mod 3 Week 8:\n",
    "# https://github.com/waysnyder/Module-3-Assignments/blob/main/Homework_08.ipynb\n",
    "# \n",
    "# =============================================================================================\n",
    "\n",
    "def run_model_classifier(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, **model_params):\n",
    "\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    \n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_preds     = model.predict(X_test)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    return mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1252e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Taken from Mod 3 Week 8:\n",
    "# https://github.com/waysnyder/Module-3-Assignments/blob/main/Homework_08.ipynb\n",
    "# \n",
    "# Global dataframe logic taken from mod 3 final project: \n",
    "# https://github.com/LeeMcFarling/Final_Project_Writeup/blob/main/Final_Project_Report.ipynb\n",
    "# =============================================================================================\n",
    "\n",
    "def run_model_classifier(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, run_comment=None, return_model=False, concat_results=False, **model_params):\n",
    "\n",
    "    global combined_results\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    model_name = model.__name__ if isinstance(model, type) else model.__class__.__name__ # Added because \n",
    "\n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    test_preds     = model.predict(X_test)\n",
    "\n",
    "    # Normal Accuracy \n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # Balanced Accuracy Metrics\n",
    "    balanced_train_accuracy = balanced_accuracy_score(y_train, train_preds)\n",
    "    balanced_test_accuracy = balanced_accuracy_score(y_test, test_preds)\n",
    "\n",
    "    results_df = pd.DataFrame([{\n",
    "        'model': model_name, \n",
    "        'model_params': model.get_params(),\n",
    "        'mean_cv_accuracy': mean_cv_accuracy,\n",
    "        'std_cv_accuracy': std_cv_accuracy,\n",
    "        'train_accuracy': train_accuracy, \n",
    "        'test_accuracy': test_accuracy,\n",
    "        'balanced_train_accuracy' : balanced_train_accuracy,\n",
    "        'balanced_test_accuracy': balanced_test_accuracy,\n",
    "        'run_comment': run_comment\n",
    "    }])\n",
    "    \n",
    "    if concat_results:\n",
    "        try:\n",
    "            combined_results = pd.concat([combined_results, results_df], ignore_index=True)\n",
    "        except NameError:\n",
    "            combined_results = results_df\n",
    "\n",
    "    return (results_df, model) if return_model else results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868e789",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4f824",
   "metadata": {},
   "source": [
    "#### **Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0feccfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Standardized Data\n",
    "X_train, X_test, y_train, y_test = train_test_split_data(BDB_All_Plays_Model_Ready, 'Inj_Occured')\n",
    "\n",
    "\n",
    "# Standardized Numeric Data\n",
    "BDB_All_Plays_Standardized = standardize_features(BDB_All_Plays_Model_Ready, target_column='Inj_Occured')\n",
    "X_train_Scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split_data(BDB_All_Plays_Standardized, 'Inj_Occured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c693db0",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da11348",
   "metadata": {},
   "source": [
    "# **Modeling**\n",
    "\n",
    "NOTE: As previously discussed in Semester 2, the primary goal of this analysis and modeling excercise is to classify whether a particular play will result in an injury, and to determine the factors that are most likely to cause this injury. Furthermore, as was *also* previously discussed, this dataset has some extreme imbalance issues (injury occurance < 2%), and as such high performance on these baseline models is NOT expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78002129",
   "metadata": {},
   "source": [
    "## **Baseline Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09bf1b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.660624</td>\n",
       "      <td>0.161201</td>\n",
       "      <td>0.593362</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>0.736741</td>\n",
       "      <td>0.504117</td>\n",
       "      <td>Baseline Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                       model_params  \\\n",
       "0  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0          0.660624         0.161201        0.593362       0.579532   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                 0.736741                0.504117   \n",
       "\n",
       "                    run_comment  \n",
       "0  Baseline Logistic Regression  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "#\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'class_weight' : 'balanced',     # attempt to balance dataset\n",
    "    'solver': 'saga',                # Doc said that this solver is better for larger datasets\n",
    "    'penalty': 'l2',                 # default \n",
    "    'max_iter' : 10000,\n",
    "    'fit_intercept': True,\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "results_df = run_model_classifier(\n",
    "    LogisticRegression,\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='Baseline Logistic Regression', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f325713",
   "metadata": {},
   "source": [
    "^ On our first runs, there were a ton of convergence warnings, so the max_iter was cranked up to 50 and tolerance was set at 1e-2 below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5891932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.640848</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>0.527769</td>\n",
       "      <td>Baseline Logistic Regression - Convergence Rem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                       model_params  \\\n",
       "0  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0          0.640848           0.0821        0.632695       0.625731   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                 0.702117                0.527769   \n",
       "\n",
       "                                         run_comment  \n",
       "0  Baseline Logistic Regression - Convergence Rem...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "#\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'class_weight' : 'balanced',        # attempt to balance dataset\n",
    "    'solver': 'saga',                   # Doc said that this solver is better for larger datasets\n",
    "    'penalty': 'l2',                    # default\n",
    "    'max_iter' : 50000,                 # Iteratively increased this until Convergence Warnings went away\n",
    "    'tol': 1e-2,                        # Another convergence warning measure\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "results_df = run_model_classifier(\n",
    "    LogisticRegression,\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='Baseline Logistic Regression - Convergence Remidiation', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e0bdb",
   "metadata": {},
   "source": [
    "Nice, we fixed the convergence issue -- now let's see how using the standardized data effects this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd657d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.698435</td>\n",
       "      <td>0.017279</td>\n",
       "      <td>0.697324</td>\n",
       "      <td>0.681871</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.50771</td>\n",
       "      <td>Baseline Logistic Regression - Scaled Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                       model_params  \\\n",
       "0  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0          0.698435         0.017279        0.697324       0.681871   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                 0.729483                 0.50771   \n",
       "\n",
       "                                  run_comment  \n",
       "0  Baseline Logistic Regression - Scaled Data  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "#\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'class_weight' : 'balanced',\n",
    "    'solver': 'saga',\n",
    "    'penalty': 'l2',\n",
    "    'max_iter' : 50000,\n",
    "    'tol': 1e-2,\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "results_df = run_model_classifier(\n",
    "    LogisticRegression,\n",
    "    X_train_Scaled,  # Scaled Now :) \n",
    "    y_train_scaled,\n",
    "    X_test_scaled,  \n",
    "    y_test_scaled,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='Baseline Logistic Regression - Scaled Data', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1364b",
   "metadata": {},
   "source": [
    "Those are some moderate improvement gains there. We can still use a different scoring accuracy metric to see if that will help even more. \n",
    "\n",
    "Re-Writing the same run_model_classifier from earlier, just with 'balanced_accuracy' as a scoring metric now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a61a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Taken from Mod 3 Week 8:\n",
    "# https://github.com/waysnyder/Module-3-Assignments/blob/main/Homework_08.ipynb\n",
    "# =============================================================================================\n",
    "\n",
    "def run_model_classifier(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, run_comment=None, return_model=False, concat_results=False, **model_params):\n",
    "\n",
    "    global combined_results\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    model_name = model.__name__ if isinstance(model, type) else model.__class__.__name__\n",
    "\n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='balanced_accuracy', cv=cv, n_jobs=n_jobs)            # NOTICE: Changed this line to 'Balanced Accuracy'\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    test_preds     = model.predict(X_test)\n",
    "\n",
    "    # Normal Accuracy \n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # Balanced Accuracy Metrics\n",
    "    balanced_train_accuracy = balanced_accuracy_score(y_train, train_preds)\n",
    "    balanced_test_accuracy = balanced_accuracy_score(y_test, test_preds)\n",
    "\n",
    "    results_df = pd.DataFrame([{\n",
    "        'model': model_name, \n",
    "        'model_params': model.get_params(),\n",
    "        'mean_cv_accuracy': mean_cv_accuracy,\n",
    "        'std_cv_accuracy': std_cv_accuracy,\n",
    "        'train_accuracy': train_accuracy, \n",
    "        'test_accuracy': test_accuracy,\n",
    "        'balanced_train_accuracy' : balanced_train_accuracy,\n",
    "        'balanced_test_accuracy': balanced_test_accuracy,\n",
    "        'run_comment': run_comment\n",
    "    }])\n",
    "    \n",
    "    if concat_results:\n",
    "        try:\n",
    "            combined_results = pd.concat([combined_results, results_df], ignore_index=True)\n",
    "        except NameError:\n",
    "            combined_results = results_df\n",
    "\n",
    "    return (results_df, model) if return_model else results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ab8c6",
   "metadata": {},
   "source": [
    "And re-running the same cell as [46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32bf65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.571458</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.697324</td>\n",
       "      <td>0.681871</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.50771</td>\n",
       "      <td>Baseline Logistic Regression - Balanced Accura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                       model_params  \\\n",
       "0  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0          0.571458         0.031973        0.697324       0.681871   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                 0.729483                 0.50771   \n",
       "\n",
       "                                         run_comment  \n",
       "0  Baseline Logistic Regression - Balanced Accura...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'class_weight' : 'balanced',\n",
    "    'solver': 'saga',\n",
    "    'penalty': 'l2',\n",
    "    'max_iter' : 60000,\n",
    "    'tol': 1e-2,\n",
    "    'random_state' : 42\n",
    "}\n",
    "\n",
    "results_df = run_model_classifier(\n",
    "    LogisticRegression,\n",
    "    X_train_Scaled,  # Scaled Now :) \n",
    "    y_train_scaled,\n",
    "    X_test_scaled,  \n",
    "    y_test_scaled,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='Baseline Logistic Regression - Balanced Accuracy Scoring', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b281aa2",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258abe79",
   "metadata": {},
   "source": [
    "#### **Baseline Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e9a331b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.660624</td>\n",
       "      <td>0.161201</td>\n",
       "      <td>0.593362</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>0.736741</td>\n",
       "      <td>0.504117</td>\n",
       "      <td>Baseline Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.640848</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.702117</td>\n",
       "      <td>0.527769</td>\n",
       "      <td>Baseline Logistic Regression - Convergence Rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.698435</td>\n",
       "      <td>0.017279</td>\n",
       "      <td>0.697324</td>\n",
       "      <td>0.681871</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.507710</td>\n",
       "      <td>Baseline Logistic Regression - Scaled Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>0.571458</td>\n",
       "      <td>0.031973</td>\n",
       "      <td>0.697324</td>\n",
       "      <td>0.681871</td>\n",
       "      <td>0.729483</td>\n",
       "      <td>0.507710</td>\n",
       "      <td>Baseline Logistic Regression - Balanced Accura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoClassifier</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 60000, 'random_stat...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975289</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Lasso Classifier - Jerry Rigged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                       model_params  \\\n",
       "0  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "1  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "2  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "3  LogisticRegression  {'C': 1.0, 'class_weight': 'balanced', 'dual':...   \n",
       "4     LassoClassifier  {'alpha': 0.1, 'max_iter': 60000, 'random_stat...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0          0.660624         0.161201        0.593362       0.579532   \n",
       "1          0.640848         0.082100        0.632695       0.625731   \n",
       "2          0.698435         0.017279        0.697324       0.681871   \n",
       "3          0.571458         0.031973        0.697324       0.681871   \n",
       "4          0.500000         0.000000        0.975289       0.976608   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                 0.736741                0.504117   \n",
       "1                 0.702117                0.527769   \n",
       "2                 0.729483                0.507710   \n",
       "3                 0.729483                0.507710   \n",
       "4                 0.500000                0.500000   \n",
       "\n",
       "                                         run_comment  \n",
       "0                       Baseline Logistic Regression  \n",
       "1  Baseline Logistic Regression - Convergence Rem...  \n",
       "2         Baseline Logistic Regression - Scaled Data  \n",
       "3  Baseline Logistic Regression - Balanced Accura...  \n",
       "4                   Lasso Classifier - Jerry Rigged   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba43030",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b7a63",
   "metadata": {},
   "source": [
    "## **Lasso Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ec01b",
   "metadata": {},
   "source": [
    "So there isn't a lasso classification class in SK-Learn. But I saw tutorials for how to use rounding to force it to exhibit classifier-like behavior here: \n",
    "\n",
    "- https://saturncloud.io/blog/python-classification-with-lasso-how-to-predict-classes/#2\n",
    "\n",
    "And then used ChatGPT to help with syntax to build a class that I could pass into our cross validation function here: \n",
    "\n",
    "- https://chatgpt.com/share/68cf6cfd-ff4c-800f-a7ab-ef0d5d769bf9\n",
    "\n",
    "While I don't think the results are going to be useful per-se, I think it would still be useful to see which feature coefficients get zero'ed out here, so we can compare and contrast this to other feature selection methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354378f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# custom lasso classification class to put into Classification Wrapper.  \n",
    "# https://chatgpt.com/share/68cf6cfd-ff4c-800f-a7ab-ef0d5d769bf9 for details on the interaction\n",
    "# =============================================================================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LassoClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, \n",
    "                alpha=1.0,\n",
    "                max_iter=1000,\n",
    "                tol=1e-4,\n",
    "                random_state=42,\n",
    "                threshold=0.5, \n",
    "                **lasso_params):\n",
    "        \"\"\"\n",
    "        Wraps Lasso regression to behave like a classifier.\n",
    "        \n",
    "        alpha: regularization strength for Lasso\n",
    "        threshold: value above which prediction is class 1, else 0\n",
    "        lasso_params: additional parameters passed to sklearn's Lasso\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.threshold = threshold\n",
    "        self.lasso_params = lasso_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Instantiate and fit underlying Lasso\n",
    "        self.model = Lasso(alpha=self.alpha, **self.lasso_params)\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Get continuous predictions and threshold them\n",
    "        y_pred_cont = self.model.predict(X)\n",
    "        return (y_pred_cont >= self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Not strictly meaningful for regression, but we can return\n",
    "        probabilities as scaled regression outputs between 0 and 1.\n",
    "        \"\"\"\n",
    "        y_pred_cont = self.model.predict(X)\n",
    "        # clip to [0, 1] range so it behaves like probabilities\n",
    "        y_proba = np.clip(y_pred_cont, 0, 1)\n",
    "        return np.column_stack([1 - y_proba, y_proba])\n",
    "\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.model.coef_\n",
    "\n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        return self.model.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b1dc7",
   "metadata": {},
   "source": [
    "Again, we don't really expect the Lasso Regressor - jerry - rigged - into - a - classifier - model to work well or give us accurate results. We're more interested in the coefficients of the features with this one. \n",
    "\n",
    "In order to get this, we will set 'return_model' to true, so we can get the coefficient information we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c44a95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LassoClassifier</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 60000, 'random_stat...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975289</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Lasso Classifier - Jerry Rigged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                                       model_params  \\\n",
       "0  LassoClassifier  {'alpha': 0.1, 'max_iter': 60000, 'random_stat...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0               0.5              0.0        0.975289       0.976608   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy  \\\n",
       "0                      0.5                     0.5   \n",
       "\n",
       "                        run_comment  \n",
       "0  Lasso Classifier - Jerry Rigged   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'alpha' : 0.1,\n",
    "    'max_iter' : 60000,\n",
    "    'tol': 1e-2,\n",
    "    'random_state' : 42\n",
    "}\n",
    "results_df, Fitted_Lasso = run_model_classifier(\n",
    "    LassoClassifier,\n",
    "    X_train_Scaled, \n",
    "    y_train_scaled,\n",
    "    X_test_scaled,  \n",
    "    y_test_scaled,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment= 'Lasso Classifier - Jerry Rigged ', \n",
    "    return_model=True,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4197ad",
   "metadata": {},
   "source": [
    "Yikes that one really overfit. But again, we're more interested in the coefficients. \n",
    "\n",
    "And now let's throw the Fitted_Lasso.coef_ in a dataframe with the X_train Scaled columns so we can get a handle on which coefficients were zero'ed out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59c3eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>down</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yardsToGo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yardlineNumber</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preSnapHomeScore</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preSnapVisitorScore</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>dropBackType_SCRAMBLE_ROLLOUT_LEFT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>dropBackType_SCRAMBLE_ROLLOUT_RIGHT</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>dropBackType_UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>pff_passCoverageType_Other</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>pff_passCoverageType_Zone</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  coef\n",
       "0                                   down   0.0\n",
       "1                              yardsToGo   0.0\n",
       "2                         yardlineNumber   0.0\n",
       "3                       preSnapHomeScore   0.0\n",
       "4                    preSnapVisitorScore   0.0\n",
       "..                                   ...   ...\n",
       "118   dropBackType_SCRAMBLE_ROLLOUT_LEFT   0.0\n",
       "119  dropBackType_SCRAMBLE_ROLLOUT_RIGHT  -0.0\n",
       "120                 dropBackType_UNKNOWN   0.0\n",
       "121           pff_passCoverageType_Other  -0.0\n",
       "122            pff_passCoverageType_Zone   0.0\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'feature' : X_train_Scaled.columns,\n",
    "    'coef' : Fitted_Lasso.coef_\n",
    "})\n",
    "\n",
    "coef_df[coef_df['coef'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b7d98",
   "metadata": {},
   "source": [
    "## **Ridge Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ac46a",
   "metadata": {},
   "source": [
    "Next, we'll try Ridge Classification -- thankfully we won't have to make a new class for this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "310726c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>{'alpha': 100, 'class_weight': None, 'copy_X':...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975289</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                                       model_params  \\\n",
       "0  RidgeClassifier  {'alpha': 100, 'class_weight': None, 'copy_X':...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0               0.5              0.0        0.975289       0.976608   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy       run_comment  \n",
       "0                      0.5                     0.5  Ridge Classifier  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================================\n",
    "# Parameters chosen from SK Learn Documentation and picked for imbalance. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\n",
    "# =============================================================================================\n",
    "\n",
    "params_ = {\n",
    "    'alpha' : 100,                  # Set to higher value to avoid overfitting\n",
    "    'max_iter' : 60000,\n",
    "    'tol': 1e-2,\n",
    "    'random_state' : 42, \n",
    "    'solver': 'sparse_cg',         # Supposed to be good for large featuresets\n",
    "    'fit_intercept': True\n",
    "}\n",
    "results_df = run_model_classifier(\n",
    "    RidgeClassifier,\n",
    "    X_train_Scaled, \n",
    "    y_train_scaled,\n",
    "    X_test_scaled,  \n",
    "    y_test_scaled,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment= 'Ridge Classifier', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e18d73",
   "metadata": {},
   "source": [
    "Just like the lasso regression, this one is grossly overfitting. The Training accuracy and test accuracy is around 97% (same accuracy as just about always choosing 'no injury') but the balanced accuracy is hovering around 50%. \n",
    "\n",
    "Again, we should be using decision trees or ensemble models or even XGBoost to try to handle this task, but for the sake of completing the analysis, we'll continue.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacebea8",
   "metadata": {},
   "source": [
    "## **Elastic Net Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe50735",
   "metadata": {},
   "source": [
    "After scouring the internet, Elastic Net is another one that is only used as a regressor. We can do the same thing as before and write a wrapper for it. \n",
    "\n",
    "Below is the one from before copied and pasted with different parameters passed into the __init__ and the fit parts of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e42f48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# Parameters obtained from: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "# ======================================================================================\n",
    "\n",
    "class ElasticNetClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,   \n",
    "                alpha=1.0,\n",
    "                l1_ratio=0.5,\n",
    "                fit_intercept=True,\n",
    "                max_iter=1000,\n",
    "                tol=1e-4,\n",
    "                selection='cyclic',\n",
    "                random_state=42,\n",
    "                threshold=0.5, \n",
    "                **params):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.selection = selection\n",
    "        self.random_state = 42\n",
    "        self.threshold = threshold\n",
    "        self.params = params\n",
    "        \n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Instantiate and fit underlying Lasso\n",
    "        self.model = ElasticNet(\n",
    "            alpha=self.alpha,\n",
    "            l1_ratio=self.l1_ratio,\n",
    "            fit_intercept=self.fit_intercept,\n",
    "            max_iter=self.max_iter,\n",
    "            tol=self.tol,\n",
    "            random_state=self.random_state,\n",
    "            selection=self.selection,\n",
    "            **self.params)\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Get continuous predictions and threshold them\n",
    "        y_pred_cont = self.model.predict(X)\n",
    "        return (y_pred_cont >= self.threshold).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Not strictly meaningful for regression, but we can return\n",
    "        probabilities as scaled regression outputs between 0 and 1.\n",
    "        \"\"\"\n",
    "        y_pred_cont = self.model.predict(X)\n",
    "        # clip to [0, 1] range so it behaves like probabilities\n",
    "        y_proba = np.clip(y_pred_cont, 0, 1)\n",
    "        return np.column_stack([1 - y_proba, y_proba])\n",
    "\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.model.coef_\n",
    "\n",
    "    @property\n",
    "    def intercept_(self):\n",
    "        return self.model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9b4dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>std_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>balanced_train_accuracy</th>\n",
       "      <th>balanced_test_accuracy</th>\n",
       "      <th>run_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNetClassifier</td>\n",
       "      <td>{'alpha': 100, 'fit_intercept': True, 'l1_rati...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975289</td>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Elastic Net Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model                                       model_params  \\\n",
       "0  ElasticNetClassifier  {'alpha': 100, 'fit_intercept': True, 'l1_rati...   \n",
       "\n",
       "   mean_cv_accuracy  std_cv_accuracy  train_accuracy  test_accuracy  \\\n",
       "0               0.5              0.0        0.975289       0.976608   \n",
       "\n",
       "   balanced_train_accuracy  balanced_test_accuracy             run_comment  \n",
       "0                      0.5                     0.5  Elastic Net Classifier  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_ = {\n",
    "    'alpha' : 100,                  # Set to higher value to avoid overfitting\n",
    "    'max_iter' : 60000,\n",
    "    'l1_ratio': 0.5,                 # Half and half between l1 and l2\n",
    "    'fit_intercept': True,\n",
    "    'tol': 1e-2,\n",
    "    'random_state' : 42, \n",
    "    'fit_intercept': True\n",
    "}\n",
    "results_df = run_model_classifier(\n",
    "    ElasticNetClassifier,\n",
    "    X_train_Scaled, \n",
    "    y_train_scaled,\n",
    "    X_test_scaled,  \n",
    "    y_test_scaled,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment= 'Elastic Net Classifier', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc10a1f",
   "metadata": {},
   "source": [
    "And it's just as bad at overfitting as the others. While decision trees, ensemble methods, and XGBoost will be better models to try in this regard in the coming weeks. \n",
    "\n",
    "Additional steps to take could be hyperparameter sweeps, different accuracy metrics, and re-sampling data to balance out the classes as was done in semester 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861390d",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce648ce8",
   "metadata": {},
   "source": [
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac656f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_comment</th>\n",
       "      <th>mean_cv_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Baseline Logistic Regression - Scaled Data</td>\n",
       "      <td>0.698435</td>\n",
       "      <td>0.697324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Baseline Logistic Regression</td>\n",
       "      <td>0.660624</td>\n",
       "      <td>0.593362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Baseline Logistic Regression - Convergence Rem...</td>\n",
       "      <td>0.640848</td>\n",
       "      <td>0.632695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Baseline Logistic Regression - Balanced Accura...</td>\n",
       "      <td>0.571458</td>\n",
       "      <td>0.697324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoClassifier</td>\n",
       "      <td>Lasso Classifier - Jerry Rigged</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.975289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNetClassifier</td>\n",
       "      <td>Elastic Net Classifier</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.975289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.975289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model                                        run_comment  \\\n",
       "2    LogisticRegression         Baseline Logistic Regression - Scaled Data   \n",
       "0    LogisticRegression                       Baseline Logistic Regression   \n",
       "1    LogisticRegression  Baseline Logistic Regression - Convergence Rem...   \n",
       "3    LogisticRegression  Baseline Logistic Regression - Balanced Accura...   \n",
       "4       LassoClassifier                   Lasso Classifier - Jerry Rigged    \n",
       "5  ElasticNetClassifier                             Elastic Net Classifier   \n",
       "6       RidgeClassifier                                   Ridge Classifier   \n",
       "\n",
       "   mean_cv_accuracy  train_accuracy  \n",
       "2          0.698435        0.697324  \n",
       "0          0.660624        0.593362  \n",
       "1          0.640848        0.632695  \n",
       "3          0.571458        0.697324  \n",
       "4          0.500000        0.975289  \n",
       "5          0.500000        0.975289  \n",
       "6          0.500000        0.975289  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results[['model', 'run_comment', 'mean_cv_accuracy', 'train_accuracy']].sort_values('mean_cv_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36003202",
   "metadata": {},
   "source": [
    "As we can see, the base Logistic regression performed the best in terms of Cross Validation Accuracy, and the model run with Scaled Data performed the best overall. In each of the cases when Lasso, Ridge, and Elastic net were attempted for the task, the training accuracy approached the same level of accuracy as just choosing 'No' every time, while the Mean CV Accuracy was barely above guessing. This suggests that all three of the models were overfitting, and preliminary changes of the parameter set in order to attempt to ameliorate this overfitting problem failed. \n",
    "\n",
    "As was said before, tree based models and tree based ensemble methods are expected to perform much better at this classification task than these models in particular, as (discounting the fact that two of these three models don't even have classification models in SKLearn) tree based and ensemble models are expected to do a much better job at dealing with the plethora of different categorical features that were one-hot encoded in previous weeks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a9f69",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfclean)",
   "language": "python",
   "name": "tfclean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
